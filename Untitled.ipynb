{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "aad16a68-1c9e-48df-8cc8-2c08680acd30",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pandas in /home/alex/.local/lib/python3.10/site-packages (2.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/alex/.local/lib/python3.10/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/lib/python3/dist-packages (from pandas) (2022.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/alex/.local/lib/python3.10/site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: numpy>=1.22.4 in /home/alex/.local/lib/python3.10/site-packages (from pandas) (2.0.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: scikit-learn in /home/alex/.local/lib/python3.10/site-packages (1.5.2)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /home/alex/.local/lib/python3.10/site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /home/alex/.local/lib/python3.10/site-packages (from scikit-learn) (1.14.1)\n",
      "Requirement already satisfied: numpy>=1.19.5 in /home/alex/.local/lib/python3.10/site-packages (from scikit-learn) (2.0.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /home/alex/.local/lib/python3.10/site-packages (from scikit-learn) (3.5.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: matplotlib in /home/alex/.local/lib/python3.10/site-packages (3.9.3)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/alex/.local/lib/python3.10/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: pillow>=8 in /usr/lib/python3/dist-packages (from matplotlib) (9.0.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/alex/.local/lib/python3.10/site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /home/alex/.local/lib/python3.10/site-packages (from matplotlib) (1.4.7)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/alex/.local/lib/python3.10/site-packages (from matplotlib) (4.55.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/alex/.local/lib/python3.10/site-packages (from matplotlib) (1.3.1)\n",
      "Requirement already satisfied: numpy>=1.23 in /home/alex/.local/lib/python3.10/site-packages (from matplotlib) (2.0.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/alex/.local/lib/python3.10/site-packages (from matplotlib) (24.2)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/lib/python3/dist-packages (from matplotlib) (2.4.7)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: tensorflow in /home/alex/.local/lib/python3.10/site-packages (2.18.0)\n",
      "Requirement already satisfied: packaging in /home/alex/.local/lib/python3.10/site-packages (from tensorflow) (24.2)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /home/alex/.local/lib/python3.10/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /home/alex/.local/lib/python3.10/site-packages (from tensorflow) (1.68.0)\n",
      "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /home/alex/.local/lib/python3.10/site-packages (from tensorflow) (0.4.1)\n",
      "Requirement already satisfied: keras>=3.5.0 in /home/alex/.local/lib/python3.10/site-packages (from tensorflow) (3.7.0)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in /home/alex/.local/lib/python3.10/site-packages (from tensorflow) (24.3.25)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /home/alex/.local/lib/python3.10/site-packages (from tensorflow) (0.37.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /home/alex/.local/lib/python3.10/site-packages (from tensorflow) (5.29.0)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /home/alex/.local/lib/python3.10/site-packages (from tensorflow) (2.32.3)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /home/alex/.local/lib/python3.10/site-packages (from tensorflow) (18.1.1)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /home/alex/.local/lib/python3.10/site-packages (from tensorflow) (2.5.0)\n",
      "Requirement already satisfied: numpy<2.1.0,>=1.26.0 in /home/alex/.local/lib/python3.10/site-packages (from tensorflow) (2.0.2)\n",
      "Requirement already satisfied: h5py>=3.11.0 in /home/alex/.local/lib/python3.10/site-packages (from tensorflow) (3.12.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /home/alex/.local/lib/python3.10/site-packages (from tensorflow) (3.4.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /home/alex/.local/lib/python3.10/site-packages (from tensorflow) (2.1.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /home/alex/.local/lib/python3.10/site-packages (from tensorflow) (1.17.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /usr/lib/python3/dist-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: tensorboard<2.19,>=2.18 in /home/alex/.local/lib/python3.10/site-packages (from tensorflow) (2.18.0)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /home/alex/.local/lib/python3.10/site-packages (from tensorflow) (0.6.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /home/alex/.local/lib/python3.10/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: setuptools in /usr/lib/python3/dist-packages (from tensorflow) (59.6.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /home/alex/.local/lib/python3.10/site-packages (from tensorflow) (4.12.2)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/lib/python3/dist-packages (from astunparse>=1.6.0->tensorflow) (0.37.1)\n",
      "Requirement already satisfied: namex in /home/alex/.local/lib/python3.10/site-packages (from keras>=3.5.0->tensorflow) (0.0.8)\n",
      "Requirement already satisfied: optree in /home/alex/.local/lib/python3.10/site-packages (from keras>=3.5.0->tensorflow) (0.13.1)\n",
      "Requirement already satisfied: rich in /home/alex/.local/lib/python3.10/site-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/lib/python3/dist-packages (from requests<3,>=2.21.0->tensorflow) (1.26.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/alex/.local/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow) (3.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests<3,>=2.21.0->tensorflow) (2020.6.20)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /home/alex/.local/lib/python3.10/site-packages (from tensorboard<2.19,>=2.18->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /home/alex/.local/lib/python3.10/site-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.1.3)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/alex/.local/lib/python3.10/site-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.7)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /home/alex/.local/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow) (3.0.2)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /home/alex/.local/lib/python3.10/site-packages (from rich->keras>=3.5.0->tensorflow) (2.18.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /home/alex/.local/lib/python3.10/site-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /home/alex/.local/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: transformers in /home/alex/.local/lib/python3.10/site-packages (4.46.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/alex/.local/lib/python3.10/site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /home/alex/.local/lib/python3.10/site-packages (from transformers) (0.4.5)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/alex/.local/lib/python3.10/site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: filelock in /home/alex/.local/lib/python3.10/site-packages (from transformers) (3.16.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/lib/python3/dist-packages (from transformers) (5.4.1)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in /home/alex/.local/lib/python3.10/site-packages (from transformers) (0.20.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/alex/.local/lib/python3.10/site-packages (from transformers) (24.2)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/alex/.local/lib/python3.10/site-packages (from transformers) (2.0.2)\n",
      "Requirement already satisfied: requests in /home/alex/.local/lib/python3.10/site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /home/alex/.local/lib/python3.10/site-packages (from transformers) (0.26.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/alex/.local/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/alex/.local/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.10.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests->transformers) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests->transformers) (2020.6.20)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/lib/python3/dist-packages (from requests->transformers) (1.26.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/alex/.local/lib/python3.10/site-packages (from requests->transformers) (3.4.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: tf-keras in /home/alex/.local/lib/python3.10/site-packages (2.18.0)\n",
      "Requirement already satisfied: tensorflow<2.19,>=2.18 in /home/alex/.local/lib/python3.10/site-packages (from tf-keras) (2.18.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /home/alex/.local/lib/python3.10/site-packages (from tensorflow<2.19,>=2.18->tf-keras) (1.6.3)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /home/alex/.local/lib/python3.10/site-packages (from tensorflow<2.19,>=2.18->tf-keras) (2.1.0)\n",
      "Requirement already satisfied: keras>=3.5.0 in /home/alex/.local/lib/python3.10/site-packages (from tensorflow<2.19,>=2.18->tf-keras) (3.7.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /home/alex/.local/lib/python3.10/site-packages (from tensorflow<2.19,>=2.18->tf-keras) (0.2.0)\n",
      "Requirement already satisfied: packaging in /home/alex/.local/lib/python3.10/site-packages (from tensorflow<2.19,>=2.18->tf-keras) (24.2)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /home/alex/.local/lib/python3.10/site-packages (from tensorflow<2.19,>=2.18->tf-keras) (0.6.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /home/alex/.local/lib/python3.10/site-packages (from tensorflow<2.19,>=2.18->tf-keras) (18.1.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /home/alex/.local/lib/python3.10/site-packages (from tensorflow<2.19,>=2.18->tf-keras) (1.68.0)\n",
      "Requirement already satisfied: setuptools in /usr/lib/python3/dist-packages (from tensorflow<2.19,>=2.18->tf-keras) (59.6.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /home/alex/.local/lib/python3.10/site-packages (from tensorflow<2.19,>=2.18->tf-keras) (0.37.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /home/alex/.local/lib/python3.10/site-packages (from tensorflow<2.19,>=2.18->tf-keras) (2.32.3)\n",
      "Requirement already satisfied: six>=1.12.0 in /usr/lib/python3/dist-packages (from tensorflow<2.19,>=2.18->tf-keras) (1.16.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /home/alex/.local/lib/python3.10/site-packages (from tensorflow<2.19,>=2.18->tf-keras) (1.17.0)\n",
      "Requirement already satisfied: tensorboard<2.19,>=2.18 in /home/alex/.local/lib/python3.10/site-packages (from tensorflow<2.19,>=2.18->tf-keras) (2.18.0)\n",
      "Requirement already satisfied: numpy<2.1.0,>=1.26.0 in /home/alex/.local/lib/python3.10/site-packages (from tensorflow<2.19,>=2.18->tf-keras) (2.0.2)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /home/alex/.local/lib/python3.10/site-packages (from tensorflow<2.19,>=2.18->tf-keras) (5.29.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /home/alex/.local/lib/python3.10/site-packages (from tensorflow<2.19,>=2.18->tf-keras) (4.12.2)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /home/alex/.local/lib/python3.10/site-packages (from tensorflow<2.19,>=2.18->tf-keras) (3.4.0)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in /home/alex/.local/lib/python3.10/site-packages (from tensorflow<2.19,>=2.18->tf-keras) (24.3.25)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /home/alex/.local/lib/python3.10/site-packages (from tensorflow<2.19,>=2.18->tf-keras) (2.5.0)\n",
      "Requirement already satisfied: h5py>=3.11.0 in /home/alex/.local/lib/python3.10/site-packages (from tensorflow<2.19,>=2.18->tf-keras) (3.12.1)\n",
      "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /home/alex/.local/lib/python3.10/site-packages (from tensorflow<2.19,>=2.18->tf-keras) (0.4.1)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/lib/python3/dist-packages (from astunparse>=1.6.0->tensorflow<2.19,>=2.18->tf-keras) (0.37.1)\n",
      "Requirement already satisfied: namex in /home/alex/.local/lib/python3.10/site-packages (from keras>=3.5.0->tensorflow<2.19,>=2.18->tf-keras) (0.0.8)\n",
      "Requirement already satisfied: rich in /home/alex/.local/lib/python3.10/site-packages (from keras>=3.5.0->tensorflow<2.19,>=2.18->tf-keras) (13.9.4)\n",
      "Requirement already satisfied: optree in /home/alex/.local/lib/python3.10/site-packages (from keras>=3.5.0->tensorflow<2.19,>=2.18->tf-keras) (0.13.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/alex/.local/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow<2.19,>=2.18->tf-keras) (3.4.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/lib/python3/dist-packages (from requests<3,>=2.21.0->tensorflow<2.19,>=2.18->tf-keras) (1.26.5)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests<3,>=2.21.0->tensorflow<2.19,>=2.18->tf-keras) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests<3,>=2.21.0->tensorflow<2.19,>=2.18->tf-keras) (2020.6.20)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /home/alex/.local/lib/python3.10/site-packages (from tensorboard<2.19,>=2.18->tensorflow<2.19,>=2.18->tf-keras) (3.1.3)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/alex/.local/lib/python3.10/site-packages (from tensorboard<2.19,>=2.18->tensorflow<2.19,>=2.18->tf-keras) (3.7)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /home/alex/.local/lib/python3.10/site-packages (from tensorboard<2.19,>=2.18->tensorflow<2.19,>=2.18->tf-keras) (0.7.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /home/alex/.local/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow<2.19,>=2.18->tf-keras) (3.0.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /home/alex/.local/lib/python3.10/site-packages (from rich->keras>=3.5.0->tensorflow<2.19,>=2.18->tf-keras) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /home/alex/.local/lib/python3.10/site-packages (from rich->keras>=3.5.0->tensorflow<2.19,>=2.18->tf-keras) (2.18.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /home/alex/.local/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow<2.19,>=2.18->tf-keras) (0.1.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting focal-loss\n",
      "  Downloading focal_loss-0.0.7-py3-none-any.whl (19 kB)\n",
      "Requirement already satisfied: tensorflow>=2.2 in /home/alex/.local/lib/python3.10/site-packages (from focal-loss) (2.18.0)\n",
      "Requirement already satisfied: numpy<2.1.0,>=1.26.0 in /home/alex/.local/lib/python3.10/site-packages (from tensorflow>=2.2->focal-loss) (2.0.2)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /home/alex/.local/lib/python3.10/site-packages (from tensorflow>=2.2->focal-loss) (2.5.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /home/alex/.local/lib/python3.10/site-packages (from tensorflow>=2.2->focal-loss) (1.68.0)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /home/alex/.local/lib/python3.10/site-packages (from tensorflow>=2.2->focal-loss) (2.32.3)\n",
      "Requirement already satisfied: packaging in /home/alex/.local/lib/python3.10/site-packages (from tensorflow>=2.2->focal-loss) (24.2)\n",
      "Requirement already satisfied: tensorboard<2.19,>=2.18 in /home/alex/.local/lib/python3.10/site-packages (from tensorflow>=2.2->focal-loss) (2.18.0)\n",
      "Requirement already satisfied: h5py>=3.11.0 in /home/alex/.local/lib/python3.10/site-packages (from tensorflow>=2.2->focal-loss) (3.12.1)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /home/alex/.local/lib/python3.10/site-packages (from tensorflow>=2.2->focal-loss) (4.12.2)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /home/alex/.local/lib/python3.10/site-packages (from tensorflow>=2.2->focal-loss) (5.29.0)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /home/alex/.local/lib/python3.10/site-packages (from tensorflow>=2.2->focal-loss) (0.6.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /home/alex/.local/lib/python3.10/site-packages (from tensorflow>=2.2->focal-loss) (1.6.3)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /home/alex/.local/lib/python3.10/site-packages (from tensorflow>=2.2->focal-loss) (3.4.0)\n",
      "Requirement already satisfied: setuptools in /usr/lib/python3/dist-packages (from tensorflow>=2.2->focal-loss) (59.6.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /usr/lib/python3/dist-packages (from tensorflow>=2.2->focal-loss) (1.16.0)\n",
      "Requirement already satisfied: keras>=3.5.0 in /home/alex/.local/lib/python3.10/site-packages (from tensorflow>=2.2->focal-loss) (3.7.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /home/alex/.local/lib/python3.10/site-packages (from tensorflow>=2.2->focal-loss) (0.37.1)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in /home/alex/.local/lib/python3.10/site-packages (from tensorflow>=2.2->focal-loss) (24.3.25)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /home/alex/.local/lib/python3.10/site-packages (from tensorflow>=2.2->focal-loss) (0.2.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /home/alex/.local/lib/python3.10/site-packages (from tensorflow>=2.2->focal-loss) (1.17.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /home/alex/.local/lib/python3.10/site-packages (from tensorflow>=2.2->focal-loss) (18.1.1)\n",
      "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /home/alex/.local/lib/python3.10/site-packages (from tensorflow>=2.2->focal-loss) (0.4.1)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /home/alex/.local/lib/python3.10/site-packages (from tensorflow>=2.2->focal-loss) (2.1.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/lib/python3/dist-packages (from astunparse>=1.6.0->tensorflow>=2.2->focal-loss) (0.37.1)\n",
      "Requirement already satisfied: optree in /home/alex/.local/lib/python3.10/site-packages (from keras>=3.5.0->tensorflow>=2.2->focal-loss) (0.13.1)\n",
      "Requirement already satisfied: namex in /home/alex/.local/lib/python3.10/site-packages (from keras>=3.5.0->tensorflow>=2.2->focal-loss) (0.0.8)\n",
      "Requirement already satisfied: rich in /home/alex/.local/lib/python3.10/site-packages (from keras>=3.5.0->tensorflow>=2.2->focal-loss) (13.9.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/alex/.local/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow>=2.2->focal-loss) (3.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests<3,>=2.21.0->tensorflow>=2.2->focal-loss) (2020.6.20)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/lib/python3/dist-packages (from requests<3,>=2.21.0->tensorflow>=2.2->focal-loss) (1.26.5)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests<3,>=2.21.0->tensorflow>=2.2->focal-loss) (3.3)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/alex/.local/lib/python3.10/site-packages (from tensorboard<2.19,>=2.18->tensorflow>=2.2->focal-loss) (3.7)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /home/alex/.local/lib/python3.10/site-packages (from tensorboard<2.19,>=2.18->tensorflow>=2.2->focal-loss) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /home/alex/.local/lib/python3.10/site-packages (from tensorboard<2.19,>=2.18->tensorflow>=2.2->focal-loss) (3.1.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /home/alex/.local/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow>=2.2->focal-loss) (3.0.2)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /home/alex/.local/lib/python3.10/site-packages (from rich->keras>=3.5.0->tensorflow>=2.2->focal-loss) (2.18.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /home/alex/.local/lib/python3.10/site-packages (from rich->keras>=3.5.0->tensorflow>=2.2->focal-loss) (3.0.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /home/alex/.local/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow>=2.2->focal-loss) (0.1.2)\n",
      "Installing collected packages: focal-loss\n",
      "Successfully installed focal-loss-0.0.7\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas\n",
    "!pip install -U scikit-learn\n",
    "!pip install -U matplotlib\n",
    "!pip install tensorflow\n",
    "!pip install transformers\n",
    "!pip install tf-keras\n",
    "!pip install focal-loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "fc188c73-e924-47cb-9e54-fd0adf1902fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49995</th>\n",
       "      <td>I thought this movie did a down right good job...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49996</th>\n",
       "      <td>Bad plot, bad dialogue, bad acting, idiotic di...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49997</th>\n",
       "      <td>I am a Catholic taught in parochial elementary...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49998</th>\n",
       "      <td>I'm going to have to disagree with the previou...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999</th>\n",
       "      <td>No one expects the Star Trek movies to be high...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50000 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review sentiment\n",
       "0      One of the other reviewers has mentioned that ...  positive\n",
       "1      A wonderful little production. <br /><br />The...  positive\n",
       "2      I thought this was a wonderful way to spend ti...  positive\n",
       "3      Basically there's a family where a little boy ...  negative\n",
       "4      Petter Mattei's \"Love in the Time of Money\" is...  positive\n",
       "...                                                  ...       ...\n",
       "49995  I thought this movie did a down right good job...  positive\n",
       "49996  Bad plot, bad dialogue, bad acting, idiotic di...  negative\n",
       "49997  I am a Catholic taught in parochial elementary...  negative\n",
       "49998  I'm going to have to disagree with the previou...  negative\n",
       "49999  No one expects the Star Trek movies to be high...  negative\n",
       "\n",
       "[50000 rows x 2 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df = pd.read_csv('data/IMDB Dataset.csv')\n",
    "df\n",
    "\n",
    "#test = df.sample(frac = 0.1)\n",
    "#train = df.drop(test.inde)x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "efa137e4-806a-4079-8981-ef1694db5cb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df[\"sentiment\"].value_counts(ascending=True).plot.barh()\n",
    "plt.title(\"Frequency of Positive and Negative Sentiment\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "c53b76c9-f9fa-4c41-9e1e-e56c9873c755",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df['isPositive'] = (df['sentiment'] == 'positive').astype(int)\n",
    "\n",
    "sentiments = df['isPositive'].values\n",
    "reviews = df['review'].values\n",
    "\n",
    "X, X_test, Y, Y_test = train_test_split(reviews,sentiments,test_size=0.2,train_size=0.8)\n",
    "X_train, X_valid, Y_train, Y_valid = train_test_split(X,Y,test_size = 0.25,train_size =0.75)\n",
    "\n",
    "# X_train, test_reviews, train_sentiments, test_sentiments = train_test_split(reviews, sentiments, test_size=.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "e0e2286e-5966-42ce-8fbb-4ceb2de78a45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>isPositive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49995</th>\n",
       "      <td>I thought this movie did a down right good job...</td>\n",
       "      <td>positive</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49996</th>\n",
       "      <td>Bad plot, bad dialogue, bad acting, idiotic di...</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49997</th>\n",
       "      <td>I am a Catholic taught in parochial elementary...</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49998</th>\n",
       "      <td>I'm going to have to disagree with the previou...</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999</th>\n",
       "      <td>No one expects the Star Trek movies to be high...</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50000 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review sentiment  isPositive\n",
       "0      One of the other reviewers has mentioned that ...  positive           1\n",
       "1      A wonderful little production. <br /><br />The...  positive           1\n",
       "2      I thought this was a wonderful way to spend ti...  positive           1\n",
       "3      Basically there's a family where a little boy ...  negative           0\n",
       "4      Petter Mattei's \"Love in the Time of Money\" is...  positive           1\n",
       "...                                                  ...       ...         ...\n",
       "49995  I thought this movie did a down right good job...  positive           1\n",
       "49996  Bad plot, bad dialogue, bad acting, idiotic di...  negative           0\n",
       "49997  I am a Catholic taught in parochial elementary...  negative           0\n",
       "49998  I'm going to have to disagree with the previou...  negative           0\n",
       "49999  No one expects the Star Trek movies to be high...  negative           0\n",
       "\n",
       "[50000 rows x 3 columns]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "cbd936ca-a235-4e5f-9be2-2b818aa4ac28",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from transformers import DistilBertTokenizerFast\n",
    "\n",
    "# Define the maximum number of words to tokenize (DistilBERT can tokenize up to 512)\n",
    "MAX_LENGTH = 128\n",
    "model_name = \"distilbert-base-uncased\"\n",
    "\n",
    "\n",
    "# Define function to encode text data in batches\n",
    "def batch_encode(tokenizer, texts, batch_size=256, max_length=MAX_LENGTH):\n",
    "    \"\"\"\"\"\"\"\"\"\n",
    "    A function that encodes a batch of texts and returns the texts'\n",
    "    corresponding encodings and attention masks that are ready to be fed \n",
    "    into a pre-trained transformer model.\n",
    "    \n",
    "    Input:\n",
    "        - tokenizer:   Tokenizer object from the PreTrainedTokenizer Class\n",
    "        - texts:       List of strings where each string represents a text\n",
    "        - batch_size:  Integer controlling number of texts in a batch\n",
    "        - max_length:  Integer controlling max number of words to tokenize in a given text\n",
    "    Output:\n",
    "        - input_ids:       sequence of texts encoded as a tf.Tensor object\n",
    "        - attention_mask:  the texts' attention mask encoded as a tf.Tensor object\n",
    "    \"\"\"\"\"\"\"\"\"\n",
    "    \n",
    "    input_ids = []\n",
    "    attention_mask = []\n",
    "    \n",
    "    for i in range(0, len(texts), batch_size):\n",
    "        batch = texts[i:i+batch_size]\n",
    "        inputs = tokenizer.batch_encode_plus(batch,\n",
    "                                             max_length=max_length,\n",
    "                                             padding='longest', #implements dynamic padding\n",
    "                                             truncation=True,\n",
    "                                             return_attention_mask=True,\n",
    "                                             return_token_type_ids=False\n",
    "                                             )\n",
    "        input_ids.extend(inputs['input_ids'])\n",
    "        attention_mask.extend(inputs['attention_mask'])\n",
    "    \n",
    "    \n",
    "    return tf.convert_to_tensor(input_ids), tf.convert_to_tensor(attention_mask)\n",
    "    \n",
    "tokenizer = DistilBertTokenizerFast.from_pretrained(model_name)\n",
    "\n",
    "# Encode X_train\n",
    "X_train_ids, X_train_attention = batch_encode(tokenizer, X_train.tolist())\n",
    "\n",
    "# Encode X_valid\n",
    "X_valid_ids, X_valid_attention = batch_encode(tokenizer, X_valid.tolist())\n",
    "\n",
    "# Encode X_test\n",
    "X_test_ids, X_test_attention = batch_encode(tokenizer, X_test.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "0c2e45d5-1102-4a6f-ac56-ddffac1efa56",
   "metadata": {},
   "outputs": [],
   "source": [
    "from focal_loss import BinaryFocalLoss\n",
    "\n",
    "MAX_LENGTH = 128\n",
    "LAYER_DROPOUT = 0.2\n",
    "LEARNING_RATE = 5e-5\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "def build_model(transformer, max_length=MAX_LENGTH):\n",
    "    \"\"\"\"\"\"\"\"\"\n",
    "    Template for building a model off of the BERT or DistilBERT architecture\n",
    "    for a binary classification task.\n",
    "    \n",
    "    Input:\n",
    "      - transformer:  a base Hugging Face transformer model object (BERT or DistilBERT)\n",
    "                      with no added classification head attached.\n",
    "      - max_length:   integer controlling the maximum number of encoded tokens \n",
    "                      in a given sequence.\n",
    "    \n",
    "    Output:\n",
    "      - model:        a compiled tf.keras.Model with added classification layers \n",
    "                      on top of the base pre-trained model architecture.\n",
    "    \"\"\"\"\"\"\"\"\"\n",
    "    \n",
    "    # Define weight initializer with a random seed to ensure reproducibility\n",
    "    weight_initializer = tf.keras.initializers.GlorotNormal(seed=RANDOM_STATE) \n",
    "    \n",
    "    # Define input layers\n",
    "    input_ids_layer = tf.keras.layers.Input(shape=(max_length,), \n",
    "                                            name='input_ids', \n",
    "                                            dtype='int32')\n",
    "    input_attention_layer = tf.keras.layers.Input(shape=(max_length,), \n",
    "                                                  name='input_attention', \n",
    "                                                  dtype='int32')\n",
    "    \n",
    "    # DistilBERT outputs a tuple where the first element at index 0\n",
    "    # represents the hidden-state at the output of the model's last layer.\n",
    "    # It is a tf.Tensor of shape (batch_size, sequence_length, hidden_size=768).\n",
    "    last_hidden_state = transformer([input_ids_layer, input_attention_layer])[0]\n",
    "    \n",
    "    # We only care about DistilBERT's output for the [CLS] token, \n",
    "    # which is located at index 0 of every encoded sequence.  \n",
    "    # Splicing out the [CLS] tokens gives us 2D data.\n",
    "    cls_token = last_hidden_state[:, 0, :]\n",
    "    \n",
    "    ##                                                 ##\n",
    "    ## Define additional dropout and dense layers here ##\n",
    "    ##                                                 ##\n",
    "    \n",
    "    # Define a single node that makes up the output layer (for binary classification)\n",
    "    output = tf.keras.layers.Dense(1, \n",
    "                                   activation='sigmoid',\n",
    "                                   kernel_initializer=weight_initializer,  \n",
    "                                   kernel_constraint=None,\n",
    "                                   bias_initializer='zeros'\n",
    "                                   )(cls_token)\n",
    "    \n",
    "    # Define the model\n",
    "    model = tf.keras.Model([input_ids_layer, input_attention_layer], output)\n",
    "    \n",
    "    # Compile the model\n",
    "    model.compile(tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE), \n",
    "                  loss=BinaryFocalLoss(gamma=2),\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "1746b65d-e8a6-4d79-a61b-711c0107ea56",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFDistilBertModel: ['vocab_layer_norm.bias', 'vocab_transform.weight', 'vocab_projector.bias', 'vocab_layer_norm.weight', 'vocab_transform.bias']\n",
      "- This IS expected if you are initializing TFDistilBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFDistilBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of TFDistilBertModel were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDistilBertModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "from transformers import TFDistilBertModel, DistilBertConfig\n",
    "\n",
    "DISTILBERT_DROPOUT = 0.2\n",
    "DISTILBERT_ATT_DROPOUT = 0\n",
    " \n",
    "# Configure DistilBERT's initialization\n",
    "config = DistilBertConfig(dropout=DISTILBERT_DROPOUT, \n",
    "                          attention_dropout=DISTILBERT_ATT_DROPOUT, \n",
    "                          output_hidden_states=True)\n",
    "                          \n",
    "# The bare, pre-trained DistilBERT transformer model outputting raw hidden-states \n",
    "# and without any specific head on top.\n",
    "distilBERT = TFDistilBertModel.from_pretrained(model_name, config=config)\n",
    "\n",
    "# Make DistilBERT layers untrainable\n",
    "for layer in distilBERT.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "model = build_model(distilBERT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "4975e0d0-a0fc-4fa5-99a3-ec8f7ea42186",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/6\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[62], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m NUM_STEPS \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(X_train) \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m BATCH_SIZE\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m train_history1 \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mX_train_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_train_attention\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mY_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mEPOCHS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mBATCH_SIZE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mNUM_STEPS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mX_valid_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_valid_attention\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY_valid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\n\u001b[1;32m     14\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tf_keras/src/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tf_keras/src/engine/training.py:1804\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1796\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1797\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1798\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1801\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m   1802\u001b[0m ):\n\u001b[1;32m   1803\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1804\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1805\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1806\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:833\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    830\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    832\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 833\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    835\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    836\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:869\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    866\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    867\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    868\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 869\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    870\u001b[0m \u001b[43m      \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_no_variable_creation_config\u001b[49m\n\u001b[1;32m    871\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    872\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_config \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    873\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    874\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[1;32m    875\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[0;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1322\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1318\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1319\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1320\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1321\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1322\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1323\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1324\u001b[0m     args,\n\u001b[1;32m   1325\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1326\u001b[0m     executing_eagerly)\n\u001b[1;32m   1327\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[1;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[1;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[1;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[1;32m    261\u001b[0m     )\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/eager/context.py:1683\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1681\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[1;32m   1682\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1683\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1684\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1685\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1686\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1687\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1688\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1689\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1690\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1691\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1692\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1693\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1697\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[1;32m   1698\u001b[0m   )\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "EPOCHS = 6\n",
    "BATCH_SIZE = 64\n",
    "NUM_STEPS = len(X_train) // BATCH_SIZE\n",
    "\n",
    "# Train the model\n",
    "train_history1 = model.fit(\n",
    "    x = [X_train_ids, X_train_attention],\n",
    "    y = Y_train,\n",
    "    epochs = EPOCHS,\n",
    "    batch_size = BATCH_SIZE,\n",
    "    steps_per_epoch = NUM_STEPS,\n",
    "    validation_data = ([X_valid_ids, X_valid_attention], Y_valid),\n",
    "    verbose=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aeace4b2-a741-4401-9812-eaeebdf946b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-29 22:37:06.386526: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-11-29 22:37:06.391645: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-11-29 22:37:06.436268: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-11-29 22:37:06.480914: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1732937826.518397   10187 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1732937826.529490   10187 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-11-29 22:37:06.622456: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-11-29 22:37:23.801252: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:152] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Modify your dataset preparation\n",
    "def prepare_dataset(dataset, batch_size=16):\n",
    "    return dataset.shuffle(100).batch(batch_size)\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((\n",
    "    dict(train_reviews_enc),\n",
    "    train_sentiments_enc\n",
    "))\n",
    "\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((\n",
    "    dict(test_reviews_enc),\n",
    "    test_sentiments_enc\n",
    "))\n",
    "\n",
    "train_dataset = prepare_dataset(train_dataset)\n",
    "test_dataset = prepare_dataset(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ef726070-6f4e-4ecb-82c9-076ca7cc8a73",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFDistilBertForSequenceClassification: ['vocab_transform.weight', 'vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_transform.bias', 'vocab_projector.bias']\n",
      "- This IS expected if you are initializing TFDistilBertForSequenceClassification from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFDistilBertForSequenceClassification from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights or buffers of the TF 2.0 model TFDistilBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['pre_classifier.weight', 'pre_classifier.bias', 'classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"tf_distil_bert_for_sequence_classification\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " distilbert (TFDistilBertMa  multiple                  66362880  \n",
      " inLayer)                                                        \n",
      "                                                                 \n",
      " pre_classifier (Dense)      multiple                  590592    \n",
      "                                                                 \n",
      " classifier (Dense)          multiple                  1538      \n",
      "                                                                 \n",
      " dropout_19 (Dropout)        multiple                  0 (unused)\n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66955010 (255.41 MB)\n",
      "Trainable params: 66955010 (255.41 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from transformers import TFDistilBertForSequenceClassification\n",
    "\n",
    "model = TFDistilBertForSequenceClassification.from_pretrained(model_name, num_labels=2)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "69bdf585-19b2-4fe7-aea3-34e22fcc86e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      " 631/2500 [======>.......................] - ETA: 4:46:11 - loss: 0.2974 - accuracy: 0.8757"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39moptimizers\u001b[38;5;241m.\u001b[39mAdam(learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5e-5\u001b[39m, epsilon\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-08\u001b[39m)\n\u001b[1;32m      2\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39moptimizer,\n\u001b[1;32m      3\u001b[0m               loss\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlosses\u001b[38;5;241m.\u001b[39mSparseCategoricalCrossentropy(from_logits\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m),\n\u001b[1;32m      4\u001b[0m               metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m----> 5\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m              \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m              \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest_dataset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m model\u001b[38;5;241m.\u001b[39msave_pretrained(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./model\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/modeling_tf_utils.py:1229\u001b[0m, in \u001b[0;36mTFPreTrainedModel.fit\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1226\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(keras\u001b[38;5;241m.\u001b[39mModel\u001b[38;5;241m.\u001b[39mfit)\n\u001b[1;32m   1227\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m   1228\u001b[0m     args, kwargs \u001b[38;5;241m=\u001b[39m convert_batch_encoding(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m-> 1229\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tf_keras/src/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tf_keras/src/engine/training.py:1804\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1796\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1797\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1798\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1801\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m   1802\u001b[0m ):\n\u001b[1;32m   1803\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1804\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1805\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1806\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:833\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    830\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    832\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 833\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    835\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    836\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:869\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    866\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    867\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    868\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 869\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    870\u001b[0m \u001b[43m      \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_no_variable_creation_config\u001b[49m\n\u001b[1;32m    871\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    872\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_config \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    873\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    874\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[1;32m    875\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[0;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1322\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1318\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1319\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1320\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1321\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1322\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1323\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1324\u001b[0m     args,\n\u001b[1;32m   1325\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1326\u001b[0m     executing_eagerly)\n\u001b[1;32m   1327\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[1;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[1;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[1;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[1;32m    261\u001b[0m     )\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/eager/context.py:1683\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1681\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[1;32m   1682\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1683\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1684\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1685\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1686\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1687\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1688\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1689\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1690\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1691\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1692\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1693\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1697\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[1;32m   1698\u001b[0m   )\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(learning_rate=5e-5, epsilon=1e-08)\n",
    "model.compile(optimizer=optimizer,\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "model.fit(train_dataset,\n",
    "              epochs=2,\n",
    "              validation_data=test_dataset)\n",
    "model.save_pretrained(\"./model\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
